## HackEd-2024 Project
**Participants:**
        Aditya Patel,
        Siddhant Goel,
        Kashish Gupta

**NOTE:**

This Github Repo doesn't contain the fully trained data model. So, the fully trained files with ML model can be accessed at the following Google Drive Link:
[HackEd 2024 - Google Drive(with Trained Data Files)](https://bit.ly/HackEd_2024_Google_Drive_Trained_Data)

**PROBLEM STATEMENT:**

We have created Real-Time Sign Language Detection using Tensorflow Object Detection and Python | Deep Learning SSD*

In this project, our collective goal was to develop a real-time sign language detection system using deep learning techniques with Tensorflow and Python. Implementing a Single Shot Multibox Detector (SSD) for object detection, specifically tailored to recognize and interpret sign language gestures was our primary focus in the project.


**DESCRIPTION:**

The primary objective of this project was to create a robust and efficient system capable of recognizing and interpreting sign language gestures in real-time using laptop camera. The implementation revolves around leveraging the power of Tensorflow's Object Detection API and utilizing the SSD architecture for accurate and fast detection of sign language gestures.


**KEY COMPONENTS:**

1. *Tensorflow Object Detection API:* This project heavily relies on Tensorflow's Object Detection API to facilitate the implementation of an accurate and efficient detection model. This API offers a rich set of pre-trained models and tools for custom model training.

2. *Single Shot Multibox Detector (SSD):* SSD is a state-of-the-art object detection algorithm known for its real-time processing capabilities. By utilizing SSD, the project aims to achieve high accuracy in recognizing and localizing sign language gestures within video streams.

**WORKFLOW:**

1. *Data Collection:* Gather a diverse dataset of sign language gestures, ensuring it covers a wide range of signs. Each sign is associated with a unique label.

2. *Model Training:* Utilize Tensorflow Object Detection API to train the SSD model on the collected sign language dataset. Fine-tune the pre-trained model to adapt to the specific nuances of sign language gestures.

3. *Real-Time Detection:* Implement a real-time sign language detection system using the trained SSD model. This involves capturing video frames, processing them through the model, and identifying sign language gestures in the live stream.

4. *Integration with User Interface:* Develop a user-friendly interface that visually displays the real-time sign language detection results. The interface should provide an intuitive and accessible way for users to interact with the system.
